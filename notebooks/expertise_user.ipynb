{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the level of expertise of each user using GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '/home/michael/Workspace/datasets/galaxy_zoo/GZ_talk_comments_notes_urls_AISSAI.json'\n",
    "output_path = '/home/michael/Workspace/datasets/galaxy_zoo/expertise.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(input_path: str) -> list:\n",
    "    with open(input_path, 'r') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'from': 'human',\n",
       "  'value': 'What is that red object? Star, galaxy, optical effect or other? '},\n",
       " {'from': 'human',\n",
       "  'value': \"Hi TiborAcs and welcome to the Zoo,\\n\\nThe red object is a foreground star from our galaxy and so is the whitish object at 5 o'clock.\\nHope this helps and happy hunting ! \"},\n",
       " {'from': 'human', 'value': '#over-lap by #local-star,'},\n",
       " {'from': 'human',\n",
       "  'value': 'Thanks! Beautiful Ã\\x83Â°Ã\\x82Â\\x9fÃ\\x82Â\\x8cÃ\\x82Â\\x9f'},\n",
       " {'from': 'human',\n",
       "  'value': \"I thought this looked like an elliptical, but it's very blue. It must be starforming so perhaps it's a spiral after all? Or a blue elliptical?\"}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = dataset[0]['conversations']\n",
    "conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is that red object? Star, galaxy, optical effect or other? '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = conversation[0]['value']\n",
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"I want you to evaluate the expertise in astronomy of the user (give a score between 0 to 10, 0 meaning he is a beginner and 10 meaning he is an full expert) based on his only one following message: %s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want you to evaluate the expertise in astronomy of the user (give a score between 0 to 10, 0 meaning he is a beginner and 10 meaning he is an full expert) based on his only one following message: What is that red object? Star, galaxy, optical effect or other? '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = prompt % user\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{'role': 'user', 'content': content}],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the given message, it is difficult to accurately evaluate the expertise in astronomy of the user. However, we can assume that the user has some basic knowledge about astronomy as they are aware of the possibility of the red object being a star, galaxy, optical effect, or something else. \\n\\nConsidering the limited information provided, it would be reasonable to assign a score of 4 to the user's expertise in astronomy. This score suggests that the user has some familiarity with common astronomical objects and concepts, but may not possess extensive knowledge or experience in the field.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi TiborAcs and welcome to the Zoo,\\n\\nThe red object is a foreground star from our galaxy and so is the whitish object at 5 o'clock.\\nHope this helps and happy hunting ! \""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = conversation[1]['value']\n",
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I want you to evaluate the expertise in astronomy of the user (give a score between 0 to 10, 0 meaning he is a beginner and 10 meaning he is an full expert) based on his only one following message: Hi TiborAcs and welcome to the Zoo,\\n\\nThe red object is a foreground star from our galaxy and so is the whitish object at 5 o'clock.\\nHope this helps and happy hunting ! \""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = prompt % user\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{'role': 'user', 'content': content}],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the given message, it is difficult to accurately evaluate the expertise in astronomy of the user. However, the user demonstrates some basic knowledge by identifying the red object as a foreground star from our galaxy and recognizing the whitish object at 5 o'clock. \\n\\nConsidering this limited information, I would assign a score of 4 out of 10, indicating a beginner level of expertise in astronomy.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galaxyzoo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
