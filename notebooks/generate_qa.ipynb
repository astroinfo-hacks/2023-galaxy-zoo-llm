{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of Questions / Answers using GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import openai\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "from absl import app, flags\n",
    "import importlib\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '/home/michael/Workspace/datasets/galaxy_zoo/GZ_talk_comments_notes_urls_AISSAI.json'\n",
    "output_path = '/home/michael/Workspace/datasets/galaxy_zoo/metadata.json'\n",
    "question_path = '/home/michael/Workspace/datasets/galaxy_zoo/questions.py'\n",
    "number_of_qa = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = importlib.util.spec_from_file_location(\"settings\", question_path)\n",
    "Questions = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(Questions)\n",
    "questions = Questions.questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Describe the following image in detail.',\n",
       " 'Provide a detailed description of the given image.',\n",
       " 'Give an elaborate explanation of the image you see.',\n",
       " 'Share a comprehensive rundown of the presented image.',\n",
       " 'Offer a thorough analysis of the image.',\n",
       " 'Explain the various aspects of the image before you.',\n",
       " 'Clarify the contents of the displayed image with great detail.',\n",
       " 'Characterize the image using a well-detailed description.',\n",
       " 'Break down the elements of the image in a detailed manner.',\n",
       " 'Walk through the important details of the image.',\n",
       " 'Portray the image with a rich, descriptive narrative.',\n",
       " 'Narrate the contents of the image with precision.',\n",
       " 'Analyze the image in a comprehensive and detailed manner.',\n",
       " 'Illustrate the image through a descriptive explanation.',\n",
       " 'Examine the image closely and share its details.',\n",
       " 'Write an exhaustive depiction of the given image.',\n",
       " 'Describe the following image concisely.',\n",
       " 'Provide a brief description of the given image.',\n",
       " 'Offer a succinct explanation of the picture presented.',\n",
       " 'Summarize the visual content of the following image.',\n",
       " 'Give a short and clear explanation of the subsequent image.',\n",
       " 'Share a concise interpretation of the image provided.',\n",
       " \"Present a compact description of the photo's key features.\",\n",
       " 'Relay a brief, clear account of the picture shown.',\n",
       " 'Render a clear and concise summary of the photo below.',\n",
       " 'Write a terse but informative summary of the following picture.',\n",
       " 'Create a compact narrative representing the image presented.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(input_path: str) -> list:\n",
    "    with open(input_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def write_to_json(data: list, output_path: str):\n",
    "    with open(output_path, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "def concat_conversation(entry: dict) -> str:\n",
    "    conversation = \"\"\n",
    "    for j in range(len(entry['conversations'])):\n",
    "        conversation += \"User: \" + entry['conversations'][j]['value'] + \"\\n\\n\"\n",
    "    return conversation\n",
    "\n",
    "def get_answer(entry, prompt: str, questions: list):\n",
    "    conversation = concat_conversation(entry)\n",
    "    question = questions[random.randint(0, len(questions) - 1)]\n",
    "\n",
    "    # Maximum number of tokens you can send to this model is 2,048 tokens per request.\n",
    "\n",
    "    content = prompt % (conversation, question)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[{'role': 'user', 'content': content}],\n",
    "                temperature=0,\n",
    "           )\n",
    "            \n",
    "            question_and_answer = [{\"from\": \"human\", \"value\": question}, {\"from\": \"gpt\", \"value\": response['choices'][0]['message'].content}]\n",
    "\n",
    "            obj = {\n",
    "                \"id\": \"{}\".format(entry['id']),\n",
    "                \"image\": \"{}.png\".format(entry['id']),\n",
    "                \"conversations\": question_and_answer\n",
    "            }\n",
    "\n",
    "            return obj\n",
    "        \n",
    "        except openai.error.RateLimitError:\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return {\n",
    "                \"id\": \"{}\".format(entry['id']),\n",
    "                \"image\": \"{}.png\".format(entry['id']),\n",
    "                \"conversations\": [{\"from\": \"human\", \"value\": question}, {\"from\": \"gpt\", \"value\": \"I am not sure what this image shows.\"}]\n",
    "            }\n",
    "        \n",
    "        time.sleep(1)\n",
    "\n",
    "def generate_summaries(dataset, output_path: str):\n",
    "    \"\"\"\n",
    "    Use multiprocessing to parallelize the generation of summaries by calling call_api over a list of prompts.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with Pool(4) as pool:\n",
    "        for result in tqdm(pool.imap(get_answer, dataset, questions), total=len(dataset), desc=\"Generating QA\"):\n",
    "            data.append(result)\n",
    "            # Write to json every 100 answers\n",
    "            if len(data) % 100 == 0:\n",
    "                write_to_json(data, output_path)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Load input JSON file\n",
    "dataset = load_dataset(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the summaries\n",
    "#summaries = generate_summaries(dataset)\n",
    "\n",
    "# Write the summaries to the output JSON file\n",
    "#write_to_json(summaries, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galaxyzoo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
