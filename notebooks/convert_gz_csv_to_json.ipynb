{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "844d37c4",
   "metadata": {},
   "source": [
    "# Convert the galaxy zoo csv dataset to a model-friendly json dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed96413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import urllib\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34d1cdb0",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "083f59a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "basename = \"/home/michael/Workspace/datasets/galaxy_zoo/\"\n",
    "input_path = os.path.join(basename, \"GZ_talk_comments_notes_urls_AISSAI.csv\")\n",
    "assert os.path.exists(input_path)\n",
    "output_path = os.path.join(basename, \"GZ_talk_comments_notes_urls_AISSAI.json\")\n",
    "data = pd.read_csv(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "939ebff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by \"subject_id\"\n",
    "grouped_data = data.groupby('subject_id')\n",
    "\n",
    "# Create a list to store the grouped data as dictionaries\n",
    "grouped_data_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5899fa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_info_by_group(subject_id: float, group: pd.DataFrame) -> dict:\n",
    "    # Get the conversations of the group as a list\n",
    "    comment_body = group['comment_body'].tolist()\n",
    "    # Get the url of the image\n",
    "    location_entry = group['locations'].iloc[0]\n",
    "    image = json.loads(location_entry)[\"0\"]\n",
    "    # Cast the subject_id as an int\n",
    "    id = str(int(subject_id))\n",
    "    # Create the conversations as a dict with the training-friendly format\n",
    "    conversations = [{\n",
    "            \"from\": \"human\",\n",
    "            \"value\": sentence\n",
    "        } for sentence in comment_body]\n",
    "\n",
    "    return {\n",
    "        \"id\": id,\n",
    "        \"image\": image,\n",
    "        \"conversations\": conversations,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f93bd7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 99591/99591 [00:04<00:00, 23328.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the progress bar\n",
    "progress_bar = tqdm(total=len(grouped_data), desc=\"Processing\")\n",
    "\n",
    "# Iterate over the groups and populate the grouped data list\n",
    "for subject_id, group in data.groupby('subject_id'):\n",
    "    # Append the group dictionary to the list\n",
    "    grouped_data_list.append(fetch_info_by_group(subject_id, group))\n",
    "\n",
    "    # Update the progress bar\n",
    "    progress_bar.update(1)\n",
    "\n",
    "# Close the progress bar\n",
    "progress_bar.close()\n",
    "\n",
    "# Convert the grouped data list to JSON\n",
    "json_data = json.dumps(grouped_data_list, indent=4)\n",
    "\n",
    "# Write the JSON data to a file\n",
    "with open(output_path, 'w') as file:\n",
    "    file.write(json_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a97e3cc7",
   "metadata": {},
   "source": [
    "### Download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8664fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16215288 https://panoptes-uploads.zooniverse.org/subject_location/7653a6ff-ea1f-4cb0-bb86-9a6f5ce0c857.jpeg\n"
     ]
    }
   ],
   "source": [
    "url = grouped_data_list[0]['image']\n",
    "id = grouped_data_list[0]['id']\n",
    "print(id, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec5ee1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(group_dict: dict, output_folder_image: str):\n",
    "    url = group_dict[\"image\"]\n",
    "    extension = os.path.splitext(url)[1]\n",
    "    id = group_dict[\"id\"]\n",
    "    print(os.path.join(output_folder_image, id + extension))\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, os.path.join(output_folder_image, id + extension))\n",
    "    except:\n",
    "        print(\"Could not download image for subject ID \" + group_dict[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df045370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/michael/Workspace/datasets/galaxy_zoo/16215288.jpeg\n"
     ]
    }
   ],
   "source": [
    "download_image(grouped_data_list[0], basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b17ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galaxyzoo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
