# Multimodal language models for GalaxyZoo image interpretation

## Rationale

You can watch the [hack presentation][telecon] by Jo during the telecon.

[telecon]: https://u-paris.zoom.us/rec/share/ibQAB_HcRwoRFxrmne3RtWUnGp3xH_bqsS9oOG0vMHZEPJidfSASYsXzR_MzNCM.0GfrQ39bReZsAScg

## Dataset

## References

Here is a list of references to get started on the subject
- [LLaVA paper](https://arxiv.org/abs/2304.08485)
- [LLaVA demo](https://llava-vl.github.io/)
-[Hugging Face Transformers] (https://huggingface.co/docs/transformers/index)